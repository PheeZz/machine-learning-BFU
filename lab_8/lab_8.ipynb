{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторная работа №8\n",
    "\n",
    "**Исследуем датасет MNIST с использованием разных фреймфорков для работы с нейронными сетями**\n",
    "\n",
    "**Задания к работе:**\n",
    "\n",
    "Установить Tensor Flow и PyTorch если вы работаете на локальной системе\n",
    "\n",
    "Часть 1. Распознавание данных MNIST используя многослойный персептрон (MLP)\n",
    "\n",
    "Используемая конфигурация сети – 3 скрытых слоя по 100 нейронов плюс выходной слой из 10 нейронов. Функции активации выбрать самостоятельно. Реализовать обучение **одинаковой**! конфигурации сети используя Tensor Flow и PyTorch. Вывести метрики классификации. Сравнить время обучения и полученные результаты.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 6s 3ms/step - loss: 0.2584 - accuracy: 0.9228 - val_loss: 0.1094 - val_accuracy: 0.9670\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1097 - accuracy: 0.9666 - val_loss: 0.0887 - val_accuracy: 0.9733\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0796 - accuracy: 0.9753 - val_loss: 0.0851 - val_accuracy: 0.9757\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0616 - accuracy: 0.9806 - val_loss: 0.1062 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0500 - accuracy: 0.9842 - val_loss: 0.0867 - val_accuracy: 0.9757\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.0899 - val_accuracy: 0.9777\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0936 - val_accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 0.0870 - val_accuracy: 0.9777\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0791 - val_accuracy: 0.9793\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 4s 2ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0852 - val_accuracy: 0.9782\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9744\n",
      "| Metric          |      Value |\n",
      "|-----------------|------------|\n",
      "| Training time   | 42.3099    |\n",
      "| Evaluation time |  0.468867  |\n",
      "| Loss            |  0.0993635 |\n",
      "| Accuracy        |  0.9744    |\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tabulate import tabulate\n",
    "from time import time\n",
    "\n",
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalise data\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert labels into one-hot vectors\n",
    "y_train = tf.one_hot(y_train, 10, dtype=tf.int32).numpy()\n",
    "y_test = tf.one_hot(y_test, 10, dtype=tf.int32).numpy()\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "tensorflow_train_time_start = time()\n",
    "model.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
    "tensorflow_train_time_end = time()\n",
    "\n",
    "# Evaluate the model on test set\n",
    "tensorflow_evaluation_time_start = time()\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "tensorflow_evaluation_time_end = time()\n",
    "\n",
    "print(tabulate([['Training time', tensorflow_train_time_end - tensorflow_train_time_start],\n",
    "                ['Evaluation time', tensorflow_evaluation_time_end -\n",
    "                    tensorflow_evaluation_time_start],\n",
    "                ['Loss', loss],\n",
    "                ['Accuracy', accuracy]],\n",
    "               headers=['Metric', 'Value'], tablefmt='github'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Metric          |    Value |\n",
      "|-----------------|----------|\n",
      "| Training time   | 92.5752  |\n",
      "| Evaluation time |  1.39677 |\n",
      "| Accuracy        |  0.9722  |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Load data\n",
    "train_data = MNIST(root='data', train=True,\n",
    "                   download=True, transform=ToTensor())\n",
    "test_data = MNIST(root='data', train=False,\n",
    "                  download=True, transform=ToTensor())\n",
    "\n",
    "# Define DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):  # Define model\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear1 = nn.Linear(28*28, 100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(100, 100)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(100, 100)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu1(self.linear1(x))\n",
    "        x = self.relu2(self.linear2(x))\n",
    "        x = self.relu3(self.linear3(x))\n",
    "        return self.linear4(x)\n",
    "\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# Train the model\n",
    "pytorch_train_time_start = time()\n",
    "for epoch in range(10):\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "pytorch_train_time_end = time()\n",
    "\n",
    "# Evaluate the model on test set\n",
    "pytorch_evaluation_time_start = time()\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    for x, y in test_loader:\n",
    "        y_pred = model(x)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "pytorch_evaluation_time_end = time()\n",
    "\n",
    "pytorch_test_accuracy = correct / total\n",
    "\n",
    "print(tabulate([['Training time', pytorch_train_time_end - pytorch_train_time_start],\n",
    "                ['Evaluation time', pytorch_evaluation_time_end -\n",
    "                    pytorch_evaluation_time_start],\n",
    "                ['Accuracy', pytorch_test_accuracy]],\n",
    "               headers=['Metric', 'Value'], tablefmt='github'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Framework   |   Training time |   Evaluation time |   Accuracy |\n",
      "|-------------|-----------------|-------------------|------------|\n",
      "| TensorFlow  |         42.3099 |          0.468867 |     0.9744 |\n",
      "| PyTorch     |         92.5752 |          1.39677  |     0.9722 |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['TensorFlow', tensorflow_train_time_end - tensorflow_train_time_start,\n",
    "                 tensorflow_evaluation_time_end - tensorflow_evaluation_time_start,\n",
    "                 accuracy],\n",
    "                ['PyTorch', pytorch_train_time_end - pytorch_train_time_start,\n",
    "                 pytorch_evaluation_time_end - pytorch_evaluation_time_start,\n",
    "                 pytorch_test_accuracy]],\n",
    "               headers=['Framework', 'Training time',\n",
    "                        'Evaluation time', 'Accuracy'],\n",
    "               tablefmt='github'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часть 2. Распознавание данных MNIST используя сверточную сеть(CNN)\n",
    "\n",
    "Используемая конфигурация сети – 2 набора слоев свертка+пуллинг (использовать свертку с размером ядра 5 и пулинг с размером 2). Один полносвязный слой на 500 узлов и выходной слой на 10. Остальные параметры выбрать самостоятельно. Внимательно изучите как связываются слои между собой! Реализовать обучение **одинаковой**! конфигурации сети используя Tensor Flow и PyTorch. Вывести метрики классификации. Сравнить время обучения и полученные результаты, а также сравнить с результатами первой части.\n",
    "\n",
    "Сделать общий вывод. Какой из фреймворков вам понравился больше и почему. Отчет должен содержать 3 файла: 1 – с реализацией на PyTorch, второй - Tensor Flow. Отчет оформить отдельным файлом (третьим)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.499\n",
      "[2] loss: 0.107\n",
      "[3] loss: 0.079\n",
      "[4] loss: 0.063\n",
      "[5] loss: 0.052\n",
      "[6] loss: 0.047\n",
      "[7] loss: 0.042\n",
      "[8] loss: 0.039\n",
      "[9] loss: 0.036\n",
      "[10] loss: 0.035\n",
      "Accuracy on test set: 99 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define device (GPU or CPU) to be used for training\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transform for data augmentation and normalization\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=2),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                      download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Define neural network architecture\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the model for a certain number of epochs\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the loss after each epoch\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / len(trainloader)))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy on test set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 15s 33ms/step - loss: 0.3671 - accuracy: 0.8878 - val_loss: 0.0797 - val_accuracy: 0.9785\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 14s 33ms/step - loss: 0.1113 - accuracy: 0.9653 - val_loss: 0.0595 - val_accuracy: 0.9830\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 14s 33ms/step - loss: 0.0862 - accuracy: 0.9733 - val_loss: 0.0501 - val_accuracy: 0.9865\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 14s 33ms/step - loss: 0.0704 - accuracy: 0.9781 - val_loss: 0.0428 - val_accuracy: 0.9887\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 14s 32ms/step - loss: 0.0626 - accuracy: 0.9808 - val_loss: 0.0385 - val_accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 14s 32ms/step - loss: 0.0551 - accuracy: 0.9829 - val_loss: 0.0385 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 14s 32ms/step - loss: 0.0500 - accuracy: 0.9844 - val_loss: 0.0357 - val_accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 14s 34ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 0.0369 - val_accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 15s 36ms/step - loss: 0.0441 - accuracy: 0.9862 - val_loss: 0.0354 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 14s 32ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.0319 - val_accuracy: 0.9905\n",
      "\n",
      "\n",
      "Test loss: 0.027531448751688004\n",
      "Test accuracy: 0.9904000163078308\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Reshape input data to three dimensions (height, width, channels)\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",\n",
    "                      input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model for a certain number of epochs\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(\"\\n\\nTest loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий вывод:\n",
    "TensorFlow понравился больше, так как он интуитивно понятнее и проще в использовании, а также имеет большое количество готовых решений для различных задач, что позволяет сократить время на разработку. Помимо этого, TensorFlow имеет большое количество документации и примеров, что также упрощает работу с ним. Также нельзя не отметить **нативную поддержку GPU**, что позволяет существенно ускорить обучение модели.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
