Лабораторная работа №7

**Исследование простейших нейронных сетей с использованием Scikit-Learn.**

Библиотека Scikit-Learn поддерживает работу с простейшим типом нейронных сетей на базе изученного в работе 6 персептрона, в частности имеется возможность использования класса многослойный персептрон (MLP) как для задач классификации, так и для задач регрессии.

К недостаткам многослойного персептрона (MLP) можно отнести:

- MLP со скрытыми слоями имеют невыпуклую функцию потерь, когда существует более одного локального минимума. Поэтому разные инициализации случайных весов могут привести к разной точности проверки.
- MLP требует настройки ряда гиперпараметров, таких как количество скрытых нейронов, слоев и итераций.
- MLP чувствителен к масштабированию функций.


**Задания:** 

**Часть 1. Изучение многослойного персептрона для задачи регресии.**

Будем использовать класс **[MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor)** применительно к используемому ранее датасету с данными по недвижимости в Боостоне. Необходимо:

1. Реализовать модель  машинного обучения  с использованием [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor). Вывести метрики модели. Сравнить полученные результаты с результатами предыдущих исследований этого датасета.
1. Исследовать зависимость качества получаемых моделейпри использовании  класса [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) от гиперпараметров влияющих на конфигурацию нейронной сети (количество слоев, скрытых нейронов). Какой из параметров оказывает наибольшее влияние на модель и почему.

**Часть 2. Изучение многослойного персептрона для задачи классификации.**

В этой части будем использовать класс **[MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)** и новый для нас датасет. Попробуем обучить нашу простую нейросеть различать рукописные цифры (датасет типа MNIST). Он включает в себя изображения цифр, написанных от руки, с соответствующими ярлыками, которые объясняют, что это за число. Каждое изображение размером 8х8 пикселей. Загрузить и посмотреть на пример можно следующим образом:

![](Aspose.Words.68e21292-7d96-4035-bb10-a225de022a4a.001.png)

Наш код  будет анализировать цифры, которые соответствуют пикселям  изображения. Вот они – 

![](Aspose.Words.68e21292-7d96-4035-bb10-a225de022a4a.002.png)

Однако перед тем, как начинать строить модель машинного обучения, нам необходимо провести предобработку данных, которая в нашем случае будет заключатся в масштабировании. В начале мы отмечали, что  MLP чувствителен к масштабированию, вспомните линейные модели и вы поймете почему. Обратите внимание, что в приведенном примере - диапазон от 0 до 15. Значения отличаются на порядок, что достаточно много. Проведем масштабирование стандартными средствами библиотеки.

![](Aspose.Words.68e21292-7d96-4035-bb10-a225de022a4a.003.png)

Теперь можно можно приступать к построению модели. Обратите внимание, что мы имеем задачу классификации по 10 классам.

Необходимо.

1. Завершить построение модели многоклассовой классификации с использованием [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier).
1. Вывести точность предсказания для каждого из классов.
